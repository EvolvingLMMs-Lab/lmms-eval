name: Bug Report
description: Report a bug in lmms-eval
labels: ["bug"]
body:
  - type: markdown
    attributes:
      value: |
        Thanks for reporting a bug. Please fill out the sections below to help us reproduce and fix the issue.

  - type: checkboxes
    attributes:
      label: Checklist
      options:
        - label: I have searched for similar issues before opening this one.
          required: true
        - label: I am using the latest version of lmms-eval.
          required: false

  - type: textarea
    id: description
    attributes:
      label: Bug Description
      description: A clear and concise description of what the bug is.
      placeholder: When I run ... I expect ... but instead ...
    validations:
      required: true

  - type: textarea
    id: reproduce
    attributes:
      label: Steps to Reproduce
      description: Provide the command or minimal code to reproduce the issue.
      placeholder: |
        1. Run `python -m lmms_eval --model ... --tasks ... --limit 8`
        2. Observe error at ...
      render: shell
    validations:
      required: true

  - type: textarea
    id: error
    attributes:
      label: Error Message / Traceback
      description: Paste the full error output.
      render: shell
    validations:
      required: false

  - type: textarea
    id: environment
    attributes:
      label: Environment
      description: |
        Please provide the following:
        - OS (e.g., Ubuntu 22.04, macOS 14)
        - Python version
        - lmms-eval version (`pip show lmms_eval`)
        - GPU / CUDA version (if relevant)
        - Torch version (if relevant)
      placeholder: |
        - OS: Ubuntu 22.04
        - Python: 3.10
        - lmms-eval: 0.6.0
        - GPU: A100 / CUDA 12.1
        - Torch: 2.2.0
    validations:
      required: true

  - type: textarea
    id: additional
    attributes:
      label: Additional Context
      description: Any other information, screenshots, or logs that might help.
    validations:
      required: false
