<p align="center" width="70%">
<img src="https://i.postimg.cc/KvkLzbF9/WX20241212-014400-2x.png">
</p>

# Suite d'√âvaluation des Grands Mod√®les Multimodaux

üåê [English](../../README.md) | [ÁÆÄ‰Ωì‰∏≠Êñá](README_zh-CN.md) | [ÁπÅÈ´î‰∏≠Êñá](README_zh-TW.md) | [Êó•Êú¨Ë™û](README_ja.md) | [ÌïúÍµ≠Ïñ¥](README_ko.md) | [Espa√±ol](README_es.md) | **Fran√ßais** | [Deutsch](README_de.md) | [Portugu√™s](README_pt-BR.md) | [–†—É—Å—Å–∫–∏–π](README_ru.md) | [Italiano](README_it.md) | [Nederlands](README_nl.md) | [Polski](README_pl.md) | [T√ºrk√ße](README_tr.md) | [ÿßŸÑÿπÿ±ÿ®Ÿäÿ©](README_ar.md) | [‡§π‡§ø‡§®‡•ç‡§¶‡•Ä](README_hi.md) | [Ti·∫øng Vi·ªát](README_vi.md) | [Indonesia](README_id.md)

[![PyPI](https://img.shields.io/pypi/v/lmms-eval)](https://pypi.org/project/lmms-eval)
![PyPI - Downloads](https://img.shields.io/pypi/dm/lmms-eval)
[![GitHub contributors](https://img.shields.io/github/contributors/EvolvingLMMs-Lab/lmms-eval)](https://github.com/EvolvingLMMs-Lab/lmms-eval/graphs/contributors)
[![issue resolution](https://img.shields.io/github/issues-closed-raw/EvolvingLMMs-Lab/lmms-eval)](https://github.com/EvolvingLMMs-Lab/lmms-eval/issues)
[![open issues](https://img.shields.io/github/issues-raw/EvolvingLMMs-Lab/lmms-eval)](https://github.com/EvolvingLMMs-Lab/lmms-eval/issues)

> Acc√©l√©rer le d√©veloppement des grands mod√®les multimodaux (LMMs) avec `lmms-eval`. Nous supportons la plupart des t√¢ches de texte, d'image, de vid√©o et d'audio.

üè† [Page d'Accueil LMMs-Lab](https://www.lmms-lab.com/) | ü§ó [Jeux de Donn√©es Huggingface](https://huggingface.co/lmms-lab) | <a href="https://emoji.gg/emoji/1684-discord-thread"><img src="https://cdn3.emoji.gg/emojis/1684-discord-thread.png" width="14px" height="14px" alt="Discord_Thread"></a> [discord/lmms-eval](https://discord.gg/zdkwKUqrPy)

üìñ [T√¢ches Support√©es (100+)](https://github.com/EvolvingLMMs-Lab/lmms-eval/blob/main/docs/current_tasks.md) | üåü [Mod√®les Support√©s (30+)](https://github.com/EvolvingLMMs-Lab/lmms-eval/tree/main/lmms_eval/models) | üìö [Documentation](../README.md)

---

## Annonces

- [2025-10] üöÄüöÄ **LMMs-Eval v0.5** est l√† ! Cette version majeure introduit une √©valuation audio compl√®te, la mise en cache des r√©ponses, 5 nouveaux mod√®les (GPT-4o Audio Preview, Gemma-3, LongViLA-R1, LLaVA-OneVision 1.5, Thyme), et plus de 50 nouvelles variantes de benchmark couvrant l'audio (Step2, VoiceBench, WenetSpeech), la vision (CharXiv, Lemonade) et le raisonnement (CSBench, SciBench, MedQA, SuperGPQA). Consultez les [notes de version](https://github.com/EvolvingLMMs-Lab/lmms-eval/blob/main/docs/lmms-eval-0.5.md) pour plus de d√©tails.
- [2025-07] üöÄüöÄ Nous avons publi√© `lmms-eval-0.4`. Consultez les [notes de version](https://github.com/EvolvingLMMs-Lab/lmms-eval/blob/main/docs/lmms-eval-0.4.md) pour plus de d√©tails.

## Pourquoi `lmms-eval` ?

Nous sommes dans un voyage passionnant vers la cr√©ation de l'Intelligence Artificielle G√©n√©rale (AGI), similaire √† l'enthousiasme de l'alunissage des ann√©es 1960. Ce voyage est propuls√© par des mod√®les de langage avanc√©s (LLMs) et des grands mod√®les multimodaux (LMMs), des syst√®mes complexes capables de comprendre, d'apprendre et d'effectuer une grande vari√©t√© de t√¢ches humaines.

Pour mesurer l'avancement de ces mod√®les, nous utilisons une vari√©t√© de benchmarks d'√©valuation. Ces benchmarks sont des outils qui nous aident √† comprendre les capacit√©s de ces mod√®les, nous montrant √† quel point nous sommes proches d'atteindre l'AGI. Cependant, trouver et utiliser ces benchmarks est un d√©fi majeur.

Dans le domaine des mod√®les de langage, le travail de [lm-evaluation-harness](https://github.com/EleutherAI/lm-evaluation-harness) a √©tabli un pr√©c√©dent pr√©cieux. Nous avons absorb√© la conception exquise et efficace de lm-evaluation-harness et introduit **lmms-eval**, un framework d'√©valuation m√©ticuleusement con√ßu pour une √©valuation coh√©rente et efficace des LMM.

## Installation

### Utilisation de uv (Recommand√© pour des environnements coh√©rents)

Nous utilisons `uv` pour la gestion des paquets afin de garantir que tous les d√©veloppeurs utilisent exactement les m√™mes versions de paquets. Tout d'abord, installez uv :
```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

Pour le d√©veloppement avec un environnement coh√©rent :
```bash
git clone https://github.com/EvolvingLMMs-Lab/lmms-eval
cd lmms-eval
# Recommand√©
uv pip install -e ".[all]"
# Si vous voulez utiliser uv sync
# uv sync  # Ceci cr√©e/met √† jour votre environnement depuis uv.lock
```

Pour ex√©cuter des commandes :
```bash
uv run python -m lmms_eval --help  # Ex√©cuter n'importe quelle commande avec uv run
```

### Installation Alternative

Pour une utilisation directe depuis Git :
```bash
uv venv eval
uv venv --python 3.12
source eval/bin/activate
# Vous devrez peut-√™tre ajouter et inclure votre propre yaml de t√¢ches si vous utilisez cette installation
uv pip install git+https://github.com/EvolvingLMMs-Lab/lmms-eval.git
```

## Utilisation

> Plus d'exemples dans [examples/models](../../examples/models)

**√âvaluation de Mod√®le Compatible OpenAI**

```bash
bash examples/models/openai_compatible.sh
bash examples/models/xai_grok.sh
```

**√âvaluation de vLLM**

```bash
bash examples/models/vllm_qwen2vl.sh
```

**√âvaluation de LLaVA-OneVision**

```bash
bash examples/models/llava_onevision.sh
```

**Plus de Param√®tres**

```bash
python3 -m lmms_eval --help
```

## Ajouter un Mod√®le et un Jeu de Donn√©es Personnalis√©s

Consultez notre [documentation](../README.md).

## Remerciements

lmms_eval est un fork de [lm-eval-harness](https://github.com/EleutherAI/lm-evaluation-harness). Nous vous recommandons de lire la [documentation de lm-eval-harness](https://github.com/EleutherAI/lm-evaluation-harness/tree/main/docs) pour des informations pertinentes.

## Citations

```shell
@misc{zhang2024lmmsevalrealitycheckevaluation,
      title={LMMs-Eval: Reality Check on the Evaluation of Large Multimodal Models}, 
      author={Kaichen Zhang and Bo Li and Peiyuan Zhang and Fanyi Pu and Joshua Adrian Cahyono and Kairui Hu and Shuai Liu and Yuanhan Zhang and Jingkang Yang and Chunyuan Li and Ziwei Liu},
      year={2024},
      eprint={2407.12772},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2407.12772}, 
}
```
