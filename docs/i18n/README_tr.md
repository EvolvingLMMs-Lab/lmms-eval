<p align="center" width="70%">
<img src="https://i.postimg.cc/KvkLzbF9/WX20241212-014400-2x.png">
</p>

# BÃ¼yÃ¼k Ã‡ok Modlu Modeller iÃ§in DeÄŸerlendirme Paketi

ğŸŒ [English](../../README.md) | [ç®€ä½“ä¸­æ–‡](README_zh-CN.md) | [ç¹é«”ä¸­æ–‡](README_zh-TW.md) | [æ—¥æœ¬èª](README_ja.md) | [í•œêµ­ì–´](README_ko.md) | [EspaÃ±ol](README_es.md) | [FranÃ§ais](README_fr.md) | [Deutsch](README_de.md) | [PortuguÃªs](README_pt-BR.md) | [Ğ ÑƒÑÑĞºĞ¸Ğ¹](README_ru.md) | [Italiano](README_it.md) | [Nederlands](README_nl.md) | [Polski](README_pl.md) | **TÃ¼rkÃ§e** | [Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©](README_ar.md) | [à¤¹à¤¿à¤¨à¥à¤¦à¥€](README_hi.md) | [Tiáº¿ng Viá»‡t](README_vi.md) | [Indonesia](README_id.md)

[![PyPI](https://img.shields.io/pypi/v/lmms-eval)](https://pypi.org/project/lmms-eval)
![PyPI - Downloads](https://img.shields.io/pypi/dm/lmms-eval)
[![GitHub contributors](https://img.shields.io/github/contributors/EvolvingLMMs-Lab/lmms-eval)](https://github.com/EvolvingLMMs-Lab/lmms-eval/graphs/contributors)
[![issue resolution](https://img.shields.io/github/issues-closed-raw/EvolvingLMMs-Lab/lmms-eval)](https://github.com/EvolvingLMMs-Lab/lmms-eval/issues)
[![open issues](https://img.shields.io/github/issues-raw/EvolvingLMMs-Lab/lmms-eval)](https://github.com/EvolvingLMMs-Lab/lmms-eval/issues)

> `lmms-eval` ile bÃ¼yÃ¼k Ã§ok modlu modellerin (LMMs) geliÅŸtirilmesini hÄ±zlandÄ±rÄ±n. Ã‡oÄŸu metin, gÃ¶rÃ¼ntÃ¼, video ve ses gÃ¶revini destekliyoruz.

ğŸ  [LMMs-Lab Ana Sayfa](https://www.lmms-lab.com/) | ğŸ¤— [Huggingface Veri Setleri](https://huggingface.co/lmms-lab) | <a href="https://emoji.gg/emoji/1684-discord-thread"><img src="https://cdn3.emoji.gg/emojis/1684-discord-thread.png" width="14px" height="14px" alt="Discord_Thread"></a> [discord/lmms-eval](https://discord.gg/zdkwKUqrPy)

ğŸ“– [Desteklenen GÃ¶revler (100+)](https://github.com/EvolvingLMMs-Lab/lmms-eval/blob/main/docs/current_tasks.md) | ğŸŒŸ [Desteklenen Modeller (30+)](https://github.com/EvolvingLMMs-Lab/lmms-eval/tree/main/lmms_eval/models) | ğŸ“š [DokÃ¼mantasyon](../README.md)

---

## Duyurular

- [2026-01] ğŸš€ğŸš€ **Ocak 2026** - Mevcut kÄ±yaslamalarda (benchmarks) uzamsal ve kompozisyonel akÄ±l yÃ¼rÃ¼tmenin hala kÃ¶r noktalar olduÄŸunu fark ettik. [CaptionQA](https://captionqa.github.io/), [SpatialTreeBench](https://github.com/THUNLP-MT/SpatialTreeBench), [SiteBench](https://sitebench.github.io/) ve [ViewSpatial](https://github.com/ViewSpatial/ViewSpatial) benchmarklarÄ±nÄ± ekledik. Uzaktan deÄŸerlendirme boru hatlarÄ± (pipeline) Ã§alÄ±ÅŸtÄ±ran ekipler iÃ§in bir HTTP deÄŸerlendirme sunucusu (#972) sunduk. Ä°statistiksel titizlik isteyenler iÃ§in CLT ve kÃ¼melenmiÅŸ standart hata tahmini (#989) Ã¶zelliklerini ekledik.
- [2025-10] ğŸš€ğŸš€ **LMMs-Eval v0.5** burada! Bu bÃ¼yÃ¼k sÃ¼rÃ¼m, kapsamlÄ± ses deÄŸerlendirmesi, yanÄ±t Ã¶nbellekleme, 5 yeni model (GPT-4o Audio Preview, Gemma-3, LongViLA-R1, LLaVA-OneVision 1.5, Thyme) ve ses (Step2, VoiceBench, WenetSpeech), gÃ¶rÃ¼ntÃ¼ (CharXiv, Lemonade) ve akÄ±l yÃ¼rÃ¼tme (CSBench, SciBench, MedQA, SuperGPQA) kapsayan 50'den fazla yeni benchmark varyantÄ± sunuyor. Detaylar iÃ§in [sÃ¼rÃ¼m notlarÄ±na](https://github.com/EvolvingLMMs-Lab/lmms-eval/blob/main/docs/lmms-eval-0.5.md) bakÄ±n.
- [2025-07] ğŸš€ğŸš€ `lmms-eval-0.4` sÃ¼rÃ¼mÃ¼nÃ¼ yayÄ±nladÄ±k. Daha fazla detay iÃ§in [sÃ¼rÃ¼m notlarÄ±na](https://github.com/EvolvingLMMs-Lab/lmms-eval/blob/main/docs/lmms-eval-0.4.md) bakÄ±n.

## Neden `lmms-eval`?

1960'larÄ±n Ay'a iniÅŸ heyecanÄ±na benzer ÅŸekilde, Yapay Genel Zeka (AGI) yaratmaya doÄŸru heyecan verici bir yolculuktayÄ±z. Bu yolculuk, Ã§ok Ã§eÅŸitli insan gÃ¶revlerini anlama, Ã¶ÄŸrenme ve gerÃ§ekleÅŸtirme kapasitesine sahip karmaÅŸÄ±k sistemler olan geliÅŸmiÅŸ bÃ¼yÃ¼k dil modelleri (LLMs) ve bÃ¼yÃ¼k Ã§ok modlu modeller (LMMs) tarafÄ±ndan desteklenmektedir.

Bu modellerin ne kadar geliÅŸmiÅŸ olduÄŸunu Ã¶lÃ§mek iÃ§in Ã§eÅŸitli deÄŸerlendirme kÄ±yaslamalarÄ± kullanÄ±yoruz. Bu kÄ±yaslamalar, bu modellerin yeteneklerini anlamamÄ±za yardÄ±mcÄ± olan, AGI'ye ne kadar yakÄ±n olduÄŸumuzu gÃ¶steren araÃ§lardÄ±r. Ancak, bu kÄ±yaslamalarÄ± bulmak ve kullanmak bÃ¼yÃ¼k bir zorluktur.

Dil modelleri alanÄ±nda, [lm-evaluation-harness](https://github.com/EleutherAI/lm-evaluation-harness) Ã§alÄ±ÅŸmasÄ± deÄŸerli bir emsal oluÅŸturmuÅŸtur. lm-evaluation-harness'Ä±n zarif ve verimli tasarÄ±mÄ±nÄ± benimsedik ve LMM'lerin tutarlÄ± ve verimli deÄŸerlendirmesi iÃ§in titizlikle hazÄ±rlanmÄ±ÅŸ bir deÄŸerlendirme Ã§erÃ§evesi olan **lmms-eval**'i tanÄ±ttÄ±k.

## Kurulum

### uv Kullanarak (TutarlÄ± ortamlar iÃ§in Ã¶nerilir)

TÃ¼m geliÅŸtiricilerin tam olarak aynÄ± paket sÃ¼rÃ¼mlerini kullanmasÄ±nÄ± saÄŸlamak iÃ§in `uv` paket yÃ¶neticisini kullanÄ±yoruz. Ã–nce uv'yi kurun:
```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

TutarlÄ± ortamla geliÅŸtirme iÃ§in:
```bash
git clone https://github.com/EvolvingLMMs-Lab/lmms-eval
cd lmms-eval
# Ã–nerilen
uv pip install -e ".[all]"
# uv sync kullanmak istiyorsanÄ±z
# uv sync  # Bu, uv.lock'tan ortamÄ±nÄ±zÄ± oluÅŸturur/gÃ¼nceller
```

KomutlarÄ± Ã§alÄ±ÅŸtÄ±rmak iÃ§in:
```bash
uv run python -m lmms_eval --help  # Herhangi bir komutu uv run ile Ã§alÄ±ÅŸtÄ±rÄ±n
```

### Alternatif Kurulum

Git'ten doÄŸrudan kullanÄ±m iÃ§in:
```bash
uv venv eval
uv venv --python 3.12
source eval/bin/activate
# Bu kurulumu kullanÄ±yorsanÄ±z kendi gÃ¶rev yaml'Ä±nÄ±zÄ± eklemeniz ve dahil etmeniz gerekebilir
uv pip install git+https://github.com/EvolvingLMMs-Lab/lmms-eval.git
```

## KullanÄ±m

> Daha fazla Ã¶rnek [examples/models](../../examples/models) iÃ§inde

**OpenAI Uyumlu Model DeÄŸerlendirmesi**

```bash
bash examples/models/openai_compatible.sh
bash examples/models/xai_grok.sh
```

**vLLM DeÄŸerlendirmesi**

```bash
bash examples/models/vllm_qwen2vl.sh
```

**LLaVA-OneVision DeÄŸerlendirmesi**

```bash
bash examples/models/llava_onevision.sh
```

**LLaVA-OneVision1_5 DeÄŸerlendirmesi**

```bash
bash examples/models/llava_onevision1_5.sh
```

**LLaMA-3.2-Vision DeÄŸerlendirmesi**

```bash
bash examples/models/llama_vision.sh
```

**Qwen2.5-VL DeÄŸerlendirmesi**

```bash
bash examples/models/qwen2_5_vl.sh
```

**BÃ¼yÃ¼k Model iÃ§in Tensor Parallel DeÄŸerlendirmesi (llava-next-72b)**

```bash
bash examples/models/tensor_parallel.sh
```

**BÃ¼yÃ¼k Model iÃ§in SGLang DeÄŸerlendirmesi (llava-next-72b)**

```bash
bash examples/models/sglang.sh
```

**Daha Fazla Parametre**

```bash
python3 -m lmms_eval --help
```

**Ortam DeÄŸiÅŸkenleri**
Deneyleri ve deÄŸerlendirmeleri Ã§alÄ±ÅŸtÄ±rmadan Ã¶nce, aÅŸaÄŸÄ±daki ortam deÄŸiÅŸkenlerini ortamÄ±nÄ±za dÄ±ÅŸa aktarmanÄ±zÄ± (export) Ã¶neririz. BazÄ±larÄ± belirli gÃ¶revlerin Ã§alÄ±ÅŸmasÄ± iÃ§in gereklidir.

```bash
export OPENAI_API_KEY="<YOUR_API_KEY>"
export HF_HOME="<Path to HF cache>"
export HF_TOKEN="<YOUR_API_KEY>"
export HF_HUB_ENABLE_HF_TRANSFER="1"
export REKA_API_KEY="<YOUR_API_KEY>"
```

**YaygÄ±n Ortam SorunlarÄ±**

Bazen httpx veya protobuf ile ilgili hatalar gibi yaygÄ±n sorunlarla karÅŸÄ±laÅŸabilirsiniz. Bu sorunlarÄ± Ã§Ã¶zmek iÃ§in Ã¶nce ÅŸunlarÄ± deneyebilirsiniz:

```bash
python3 -m pip install httpx==0.23.3;
python3 -m pip install protobuf==3.20;
# numpy==2.x kullanÄ±yorsanÄ±z bazen hatalara neden olabilir
python3 -m pip install numpy==1.26;
# Tokenizer'Ä±n Ã§alÄ±ÅŸmasÄ± iÃ§in bazen sentencepiece gereklidir
python3 -m pip install sentencepiece;
```

## Ã–zel Model ve Veri Seti Ekleme

[DokÃ¼mantasyonumuza](../README.md) bakÄ±n.

## TeÅŸekkÃ¼rler

lmms_eval, [lm-eval-harness](https://github.com/EleutherAI/lm-evaluation-harness)'in bir Ã§atalÄ±dÄ±r. Ä°lgili bilgiler iÃ§in lm-eval-harness [dokÃ¼mantasyonunu](https://github.com/EleutherAI/lm-evaluation-harness/tree/main/docs) okumanÄ±zÄ± Ã¶neririz.

## AtÄ±flar

```shell
@misc{zhang2024lmmsevalrealitycheckevaluation,
      title={LMMs-Eval: Reality Check on the Evaluation of Large Multimodal Models}, 
      author={Kaichen Zhang and Bo Li and Peiyuan Zhang and Fanyi Pu and Joshua Adrian Cahyono and Kairui Hu and Shuai Liu and Yuanhan Zhang and Jingkang Yang and Chunyuan Li and Ziwei Liu},
      year={2024},
      eprint={2407.12772},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2407.12772}, 
}

@misc{lmms_eval2024,
    title={LMMs-Eval: Accelerating the Development of Large Multimoal Models},
    url={https://github.com/EvolvingLMMs-Lab/lmms-eval},
    author={Bo Li*, Peiyuan Zhang*, Kaichen Zhang*, Fanyi Pu*, Xinrun Du, Yuhao Dong, Haotian Liu, Yuanhan Zhang, Ge Zhang, Chunyuan Li and Ziwei Liu},
    publisher    = {Zenodo},
    version      = {v0.1.0},
    month={March},
    year={2024}
}
```

