<p align="center" width="70%">
<img src="https://i.postimg.cc/KvkLzbF9/WX20241212-014400-2x.png">
</p>

# B·ªô C√¥ng C·ª• ƒê√°nh Gi√° M√¥ H√¨nh ƒêa Ph∆∞∆°ng Th·ª©c L·ªõn

üåê [English](../../README.md) | [ÁÆÄ‰Ωì‰∏≠Êñá](README_zh-CN.md) | [ÁπÅÈ´î‰∏≠Êñá](README_zh-TW.md) | [Êó•Êú¨Ë™û](README_ja.md) | [ÌïúÍµ≠Ïñ¥](README_ko.md) | [Espa√±ol](README_es.md) | [Fran√ßais](README_fr.md) | [Deutsch](README_de.md) | [Portugu√™s](README_pt-BR.md) | [–†—É—Å—Å–∫–∏–π](README_ru.md) | [Italiano](README_it.md) | [Nederlands](README_nl.md) | [Polski](README_pl.md) | [T√ºrk√ße](README_tr.md) | [ÿßŸÑÿπÿ±ÿ®Ÿäÿ©](README_ar.md) | [‡§π‡§ø‡§®‡•ç‡§¶‡•Ä](README_hi.md) | **Ti·∫øng Vi·ªát** | [Indonesia](README_id.md)

[![PyPI](https://img.shields.io/pypi/v/lmms-eval)](https://pypi.org/project/lmms-eval)
![PyPI - Downloads](https://img.shields.io/pypi/dm/lmms-eval)
[![GitHub contributors](https://img.shields.io/github/contributors/EvolvingLMMs-Lab/lmms-eval)](https://github.com/EvolvingLMMs-Lab/lmms-eval/graphs/contributors)
[![issue resolution](https://img.shields.io/github/issues-closed-raw/EvolvingLMMs-Lab/lmms-eval)](https://github.com/EvolvingLMMs-Lab/lmms-eval/issues)
[![open issues](https://img.shields.io/github/issues-raw/EvolvingLMMs-Lab/lmms-eval)](https://github.com/EvolvingLMMs-Lab/lmms-eval/issues)

> TƒÉng t·ªëc ph√°t tri·ªÉn c√°c m√¥ h√¨nh ƒëa ph∆∞∆°ng th·ª©c l·ªõn (LMMs) v·ªõi `lmms-eval`. Ch√∫ng t√¥i h·ªó tr·ª£ h·∫ßu h·∫øt c√°c t√°c v·ª• vƒÉn b·∫£n, h√¨nh ·∫£nh, video v√† √¢m thanh.

üè† [Trang Ch·ªß LMMs-Lab](https://www.lmms-lab.com/) | ü§ó [B·ªô D·ªØ Li·ªáu Huggingface](https://huggingface.co/lmms-lab) | <a href="https://emoji.gg/emoji/1684-discord-thread"><img src="https://cdn3.emoji.gg/emojis/1684-discord-thread.png" width="14px" height="14px" alt="Discord_Thread"></a> [discord/lmms-eval](https://discord.gg/zdkwKUqrPy)

üìñ [T√°c V·ª• ƒê∆∞·ª£c H·ªó Tr·ª£ (100+)](https://github.com/EvolvingLMMs-Lab/lmms-eval/blob/main/docs/current_tasks.md) | üåü [M√¥ H√¨nh ƒê∆∞·ª£c H·ªó Tr·ª£ (30+)](https://github.com/EvolvingLMMs-Lab/lmms-eval/tree/main/lmms_eval/models) | üìö [T√†i Li·ªáu](../README.md)

---

## Th√¥ng B√°o

- [2025-10] üöÄüöÄ **LMMs-Eval v0.5** ƒë√£ ra m·∫Øt! B·∫£n ph√°t h√†nh ch√≠nh n√†y gi·ªõi thi·ªáu ƒë√°nh gi√° √¢m thanh to√†n di·ªán, b·ªô nh·ªõ ƒë·ªám ph·∫£n h·ªìi, 5 m√¥ h√¨nh m·ªõi (GPT-4o Audio Preview, Gemma-3, LongViLA-R1, LLaVA-OneVision 1.5, Thyme), v√† h∆°n 50 bi·∫øn th·ªÉ benchmark m·ªõi bao g·ªìm √¢m thanh (Step2, VoiceBench, WenetSpeech), th·ªã gi√°c (CharXiv, Lemonade), v√† suy lu·∫≠n (CSBench, SciBench, MedQA, SuperGPQA). Xem [ghi ch√∫ ph√°t h√†nh](https://github.com/EvolvingLMMs-Lab/lmms-eval/blob/main/docs/lmms-eval-0.5.md) ƒë·ªÉ bi·∫øt chi ti·∫øt.
- [2025-07] üöÄüöÄ Ch√∫ng t√¥i ƒë√£ ph√°t h√†nh `lmms-eval-0.4`. Xem [ghi ch√∫ ph√°t h√†nh](https://github.com/EvolvingLMMs-Lab/lmms-eval/blob/main/docs/lmms-eval-0.4.md) ƒë·ªÉ bi·∫øt th√™m chi ti·∫øt.

## T·∫°i Sao Ch·ªçn `lmms-eval`?

Ch√∫ng ta ƒëang trong m·ªôt h√†nh tr√¨nh th√∫ v·ªã h∆∞·ªõng t·ªõi vi·ªác t·∫°o ra Tr√≠ Tu·ªá Nh√¢n T·∫°o T·ªïng Qu√°t (AGI), t∆∞∆°ng t·ª± nh∆∞ s·ª± nhi·ªát t√¨nh c·ªßa cu·ªôc ƒë·ªï b·ªô l√™n M·∫∑t TrƒÉng nh·ªØng nƒÉm 1960. H√†nh tr√¨nh n√†y ƒë∆∞·ª£c th√∫c ƒë·∫©y b·ªüi c√°c m√¥ h√¨nh ng√¥n ng·ªØ l·ªõn ti√™n ti·∫øn (LLMs) v√† c√°c m√¥ h√¨nh ƒëa ph∆∞∆°ng th·ª©c l·ªõn (LMMs), l√† c√°c h·ªá th·ªëng ph·ª©c t·∫°p c√≥ kh·∫£ nƒÉng hi·ªÉu, h·ªçc h·ªèi v√† th·ª±c hi·ªán nhi·ªÅu lo·∫°i nhi·ªám v·ª• c·ªßa con ng∆∞·ªùi.

ƒê·ªÉ ƒëo l∆∞·ªùng m·ª©c ƒë·ªô ti√™n ti·∫øn c·ªßa c√°c m√¥ h√¨nh n√†y, ch√∫ng t√¥i s·ª≠ d·ª•ng nhi·ªÅu benchmark ƒë√°nh gi√° kh√°c nhau. C√°c benchmark n√†y l√† c√¥ng c·ª• gi√∫p ch√∫ng t√¥i hi·ªÉu kh·∫£ nƒÉng c·ªßa c√°c m√¥ h√¨nh n√†y, cho ch√∫ng t√¥i th·∫•y ch√∫ng ta ƒëang g·∫ßn ƒë·∫øn AGI nh∆∞ th·∫ø n√†o. Tuy nhi√™n, vi·ªác t√¨m ki·∫øm v√† s·ª≠ d·ª•ng c√°c benchmark n√†y l√† m·ªôt th√°ch th·ª©c l·ªõn.

Trong lƒ©nh v·ª±c m√¥ h√¨nh ng√¥n ng·ªØ, c√¥ng tr√¨nh c·ªßa [lm-evaluation-harness](https://github.com/EleutherAI/lm-evaluation-harness) ƒë√£ t·∫°o ti·ªÅn l·ªá qu√Ω b√°u. Ch√∫ng t√¥i ƒë√£ ti·∫øp thu thi·∫øt k·∫ø tinh t·∫ø v√† hi·ªáu qu·∫£ c·ªßa lm-evaluation-harness v√† gi·ªõi thi·ªáu **lmms-eval**, m·ªôt framework ƒë√°nh gi√° ƒë∆∞·ª£c x√¢y d·ª±ng t·ªâ m·ªâ ƒë·ªÉ ƒë√°nh gi√° LMM m·ªôt c√°ch nh·∫•t qu√°n v√† hi·ªáu qu·∫£.

## C√†i ƒê·∫∑t

### S·ª≠ D·ª•ng uv (Khuy·∫øn ngh·ªã cho m√¥i tr∆∞·ªùng nh·∫•t qu√°n)

Ch√∫ng t√¥i s·ª≠ d·ª•ng `uv` ƒë·ªÉ qu·∫£n l√Ω g√≥i nh·∫±m ƒë·∫£m b·∫£o t·∫•t c·∫£ c√°c nh√† ph√°t tri·ªÉn s·ª≠ d·ª•ng c√πng phi√™n b·∫£n g√≥i. ƒê·∫ßu ti√™n, c√†i ƒë·∫∑t uv:
```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

ƒê·ªÉ ph√°t tri·ªÉn v·ªõi m√¥i tr∆∞·ªùng nh·∫•t qu√°n:
```bash
git clone https://github.com/EvolvingLMMs-Lab/lmms-eval
cd lmms-eval
# Khuy·∫øn ngh·ªã
uv pip install -e ".[all]"
# N·∫øu b·∫°n mu·ªën s·ª≠ d·ª•ng uv sync
# uv sync  # ƒêi·ªÅu n√†y t·∫°o/c·∫≠p nh·∫≠t m√¥i tr∆∞·ªùng c·ªßa b·∫°n t·ª´ uv.lock
```

ƒê·ªÉ ch·∫°y l·ªánh:
```bash
uv run python -m lmms_eval --help  # Ch·∫°y b·∫•t k·ª≥ l·ªánh n√†o v·ªõi uv run
```

### C√†i ƒê·∫∑t Thay Th·∫ø

ƒê·ªÉ s·ª≠ d·ª•ng tr·ª±c ti·∫øp t·ª´ Git:
```bash
uv venv eval
uv venv --python 3.12
source eval/bin/activate
# B·∫°n c√≥ th·ªÉ c·∫ßn th√™m v√† bao g·ªìm yaml t√°c v·ª• c·ªßa ri√™ng m√¨nh n·∫øu s·ª≠ d·ª•ng c√†i ƒë·∫∑t n√†y
uv pip install git+https://github.com/EvolvingLMMs-Lab/lmms-eval.git
```

## C√°ch S·ª≠ D·ª•ng

> Xem th√™m v√≠ d·ª• t·∫°i [examples/models](../../examples/models)

**ƒê√°nh Gi√° M√¥ H√¨nh T∆∞∆°ng Th√≠ch OpenAI**

```bash
bash examples/models/openai_compatible.sh
bash examples/models/xai_grok.sh
```

**ƒê√°nh Gi√° vLLM**

```bash
bash examples/models/vllm_qwen2vl.sh
```

**ƒê√°nh Gi√° LLaVA-OneVision**

```bash
bash examples/models/llava_onevision.sh
```

**Th√™m Tham S·ªë**

```bash
python3 -m lmms_eval --help
```

## Th√™m M√¥ H√¨nh v√† B·ªô D·ªØ Li·ªáu T√πy Ch·ªânh

Xem [t√†i li·ªáu](../README.md) c·ªßa ch√∫ng t√¥i.

## L·ªùi C·∫£m ∆†n

lmms_eval l√† m·ªôt nh√°nh c·ªßa [lm-eval-harness](https://github.com/EleutherAI/lm-evaluation-harness). Ch√∫ng t√¥i khuy·∫øn ngh·ªã ƒë·ªçc [t√†i li·ªáu c·ªßa lm-eval-harness](https://github.com/EleutherAI/lm-evaluation-harness/tree/main/docs) ƒë·ªÉ bi·∫øt th√¥ng tin li√™n quan.

## Tr√≠ch D·∫´n

```shell
@misc{zhang2024lmmsevalrealitycheckevaluation,
      title={LMMs-Eval: Reality Check on the Evaluation of Large Multimodal Models}, 
      author={Kaichen Zhang and Bo Li and Peiyuan Zhang and Fanyi Pu and Joshua Adrian Cahyono and Kairui Hu and Shuai Liu and Yuanhan Zhang and Jingkang Yang and Chunyuan Li and Ziwei Liu},
      year={2024},
      eprint={2407.12772},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2407.12772}, 
}
```
