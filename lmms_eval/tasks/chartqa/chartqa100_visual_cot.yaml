# ChartQA 100-sample subset - Visual CoT Version
# Sample distribution: human_test: 58 (58.0%), augmented_test: 42 (42.0%)

dataset_path: parquet
dataset_kwargs:
  data_files: /blob/lmms-eval-dataset/chartqa100.parquet
task: "chartqa100_visual_cot"
test_split: train
output_type: generate_until
doc_to_visual: !function utils.chartqa_doc_to_visual
doc_to_text: !function utils.chartqa_doc_to_text_visual_cot
doc_to_target: "answer"
generation_kwargs:
  max_new_tokens: 16
  temperature: 0
  do_sample: False
process_results: !function utils.chartqa_process_results
metric_list:
  - metric: relaxed_overall
    aggregation: mean
    higher_is_better: true
  - metric: relaxed_human_split
    aggregation: mean
    higher_is_better: true
  - metric: relaxed_augmented_split
    aggregation: mean
    higher_is_better: true

lmms_eval_specific_kwargs:
  default:
    pre_prompt: ""
    post_prompt: "\nAnswer the question with a single word."
  bagel_visual_cot:
    pre_prompt: ""
    post_prompt: "\nAnswer the question with a single word."
    # Stage 1: Image generation parameters
    stage1_cfg_text_scale: 4.0
    stage1_cfg_interval: 0.4
    stage1_timestep_shift: 3.0
    stage1_num_timesteps: 50
    stage1_cfg_renorm_min: 0.0
    stage1_cfg_renorm_type: "global"
    stage1_image_ratio: "1:1"
    # Stage 2: Visual understanding parameters
    stage2_max_new_tokens: 16
    stage2_temperature: 0.0
    stage2_do_sample: false
    # Save intermediate artifacts for debugging
    save_intermediate: true

metadata:
  version: 1.0
  description: "ChartQA 100-sample with Visual CoT"
  original_dataset: "lmms-lab/ChartQA"
  num_samples: 100
  seed: 42
  prompt_type: visual_cot
