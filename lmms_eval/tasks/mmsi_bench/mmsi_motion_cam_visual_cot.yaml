dataset_path: parquet

task: "mmsi_motion_cam_visual_cot"
dataset_kwargs:
  data_files: /blob/lmms-eval-dataset/mmsi_bench_5tasks/motion_cam.parquet
test_split: train
output_type: generate_until
doc_to_visual: !function utils.msr_doc_to_visual
doc_to_text: !function utils.msr_doc_to_text_with_gen_prompt
doc_to_target: "answer"
process_results: !function utils.msr_process_results

lmms_eval_specific_kwargs:
  default:
    # Stage 1: Image generation prompt
    generation_prompt: "Create a visualization showing camera motion analysis. Draw arrows indicating the direction of camera movement/rotation, highlight reference points that shift between frames, and annotate the type of camera motion (pan, tilt, zoom, dolly, etc.)."
    # Stage 2: Question answering prompt
    pre_prompt: "You are given consecutive first-person perspective images and a visualization of camera motion. Use both to determine how the camera (viewpoint) is moving or rotating.\n\n"
    post_prompt: "\n\nBased on your analysis of camera motion, answer with the option's letter from the given choices directly. Enclose the option's letter within ``."

generation_kwargs:
  max_new_tokens: 2048
  temperature: 0
  do_sample: False

metric_list:
  - metric: Motion (Cam.)
    aggregation: !function utils.msr_aggregate_results
    higher_is_better: true

metadata:
  - version: 0.0
  - description: "MMSI-Bench Motion (Camera) task with visual CoT two-stage inference"
