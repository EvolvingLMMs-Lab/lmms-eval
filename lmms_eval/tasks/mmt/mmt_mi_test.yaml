dataset_path: lmms-lab/MMT_MI-Benchmark
dataset_kwargs:
  token: True
task: "mmt_mi_test"
test_split: test
doc_to_visual: !function utils.mmt_doc_to_visual
doc_to_text: !function utils.mmt_doc_to_text
doc_to_choice: !function utils.mmt_doc_to_choice
doc_to_target: !function utils.mmt_doc_to_target
process_results: !function utils.mmt_process_results
metric_list:
  - metric: submission
    aggregation: !function utils.mmt_test_aggregate_results_for_submission
    higher_is_better: true
include: _default_template_yaml