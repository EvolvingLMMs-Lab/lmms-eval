dataset_path: lmms-lab/MMT_MI-Benchmark
dataset_kwargs:
  token: True
task: "mmt_mi_val"
test_split: val
doc_to_visual: !function utils_mi.mmt_doc_to_visual
doc_to_text: !function utils_mi.mmt_doc_to_text
doc_to_choice: !function utils_mi.mmt_doc_to_choice
doc_to_target: !function utils_mi.mmt_doc_to_target
process_results: !function utils_mi.mmt_process_results
metric_list:
  - metric: accuracy
    aggregation: !function utils_mi.mmt_aggregate_results
    higher_is_better: true
include: _default_template_yaml