task: "mmiasd_instruction"
test_split: test
dataset_name: mmiasd_base
model_specific_prompt_kwargs:
  default:
    pre_prompt: ""
    post_prompt: "\nIf all the options are incorrect, answer \"F. None of the above\"."
include: _default_template_mmupd_yaml
metric_list:
  - metric: gpt_eval_score
    aggregation: !function utils.mmiasd_instruction
    higher_is_better: true