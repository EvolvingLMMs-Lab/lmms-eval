dataset_path: lmms-lab/SuperGPQA
dataset_kwargs:
  token: True
test_split: test
task: "scibench_multishot"

doc_to_text: !function utils.scibench_multishot_doc_to_text
doc_to_target: "answer_number"

lmms_eval_specific_kwargs:
  default:
    pre_prompt: ""
    post_prompt: ""

metric_list:
  - metric: accuracy
    aggregation: mean
    higher_is_better: true

process_results: !function utils.scibench_process_results

metadata:
  version: 0.0