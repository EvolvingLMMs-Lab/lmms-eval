# Uni-MMMU Maze 100 samples - Visual CoT Version
dataset_path: parquet
dataset_kwargs:
  data_files: /home/aiscuser/lmms-eval-dataset/uni_mmmu_maze100.parquet
task: "uni_mmmu_maze100_visual_cot"
test_split: train
output_type: generate_until

doc_to_visual: !function utils.maze_doc_to_visual
doc_to_text: !function utils.maze_doc_to_text_visual_cot
doc_to_target: "steps"

process_results: !function utils.maze_process_results

generation_kwargs:
  max_new_tokens: 4096
  do_sample: false
  temperature: 0.0

lmms_eval_specific_kwargs:
  bagel_interleaved:
    # Task type: maze generates step-by-step movement images
    # num_images dynamically determined from doc["steps"]
    task_type: "maze"
    num_images: 10  # Fallback if ground truth not available
    # Image generation parameters
    cfg_text_scale: 4.0
    cfg_interval: 0.4
    timestep_shift: 3.0
    num_timesteps: 50

metric_list:
  - metric: maze_text_exact
    aggregation: mean
    higher_is_better: true
  - metric: maze_text_frame_acc
    aggregation: mean
    higher_is_better: true

metadata:
  version: 1.0
  num_samples: 100
  seed: 42
  prompt_type: visual_cot
  description: "Uni-MMMU Maze with Visual CoT"
