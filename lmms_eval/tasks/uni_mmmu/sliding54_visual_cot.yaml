# Uni-MMMU Sliding 54 samples - Visual CoT Version
dataset_path: parquet
dataset_kwargs:
  data_files: /home/aiscuser/lmms-eval-dataset/uni_mmmu_sliding54.parquet
task: "uni_mmmu_sliding54_visual_cot"
test_split: train
output_type: generate_until

doc_to_visual: !function utils.sliding_doc_to_visual
doc_to_text: !function utils.sliding_doc_to_text_visual_cot
doc_to_target: "steps_words"

process_results: !function utils.sliding_process_results

generation_kwargs:
  max_new_tokens: 4096
  do_sample: false
  temperature: 0.0

lmms_eval_specific_kwargs:
  bagel_interleaved:
    # Task type: sliding generates step-by-step puzzle state images
    # num_images dynamically determined from doc["steps_words"]
    task_type: "sliding"
    num_images: 10  # Fallback if ground truth not available
    # Image generation parameters
    cfg_text_scale: 4.0
    cfg_interval: 0.4
    timestep_shift: 3.0
    num_timesteps: 50

metric_list:
  - metric: sliding_text_exact
    aggregation: mean
    higher_is_better: true
  - metric: sliding_text_frame_acc
    aggregation: mean
    higher_is_better: true

metadata:
  version: 1.0
  num_samples: 54
  seed: 42
  prompt_type: visual_cot
  description: "Uni-MMMU Sliding with Visual CoT"
